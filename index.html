<!DOCTYPE html>
<html lang="en">

<head>
    <title>Manish Bhattarai</title>
    <description>Manish Bhattarai Personal Website</description>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="manish, bhattarai, lanl, los alamos natioanl laboratory, los alamos, computer vision, deep-learning, machine-learning, machine learning, deep learning, artificial intelligence, AI, tensor-factorizations , tensor factorizations , high performance computing, hpc , unm , firefighting , situational awareness , ">
    <meta name="author" content="Manish Bhattarai">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-151327506-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-151327506-1');
    </script>

    <script>
        /**
         * Function that registers a click on an outbound link in Analytics.
         * This function takes a valid URL string as an argument, and uses that URL string
         * as the event label. Setting the transport method to 'beacon' lets the hit be sent
         * using 'navigator.sendBeacon' in browser that support it.
         */
        var getOutboundLink = function(url) {
            gtag('event', 'click', {
                'event_category': 'outbound',
                'event_label': url,
                'transport_type': 'beacon',
                'event_callback': function() {
                    document.location = url;
                }
            });
        }
    </script>

    <style>
        .newflag {
            background-color: #C0B283;
            color: #ffffff;
            padding: 2px 5px;
            border-radius: 5px;
            border: 2px solid #C0B283;
            font: 600 16px Montserrat, sans-serif;
            font-family: Montserrat, sans-serif;
        }
    </style>

    <style>
        body {
            font: 400 15px Montserrat, sans-serif;
            font-family: Montserrat, sans-serif;
            line-height: 1.8;
            color: #818181;
        }
        
        img {
            width: 100%;
            height: auto;
        }
        
        h2 {
            font-size: 24px;
            text-transform: uppercase;
            font-weight: 600;
            margin-bottom: 20px;
            text-align: center;
            font-family: Montserrat, sans-serif;
            letter-spacing: 4px;
        }
        
        h3 {
            font-size: 22px;
            font-weight: 400;
            margin-bottom: 20px;
            text-align: left;
        }
        
        h4 {
            font-size: 19px;
            line-height: 1.375em;
            font-weight: 400;
            margin-bottom: 20px;
            text-align: left;
        }
        
        h5 {
            font-size: 16px;
            line-height: 1.375em;
            font-weight: 400;
            margin-bottom: 15px;
        }
        
        h6 {
            font-size: 15px;
            line-height: 1.375em;
            font-weight: 400;
            margin-bottom: 14px;
            text-align: right;
        }
        
        .jumbotron {
            background-image: url("images/robot.jpg");
            background-size: 100% auto;
            background-align: center;
            padding: 100px 25px;
            font-family: Montserrat, sans-serif;
        }
        
        .container-fluid {
            padding: 60px 50px;
        }
        
        .section-navbar {
            color: #C0B283;
            background-color: #FFFFFF;
        }
        
        .section-default {
            color: #373737;
            background-color: #F4F4F4;
        }
        
        .section-about-me,
        .section-about-me h4,
        .section-about-me a {
            color: #373737;
            background-color: #F4F4F4;
            text-align: justify;
			font-size: 20px;
            line-height: 1.8em;
			
        }
        
        .section-recent-news {
            color: #373737;
            background-color: #ede6de;
        }
        
        .section-research {
            color: #373737;
            background-color: #F4F4F4;
            text-align: justify;
        }
        
        .section-research h3 {
            text-align: center;
        }
        
        .section-research h4 {
            text-align: center;
        }
        
        .section-publications,
        .section-publications a {
            color: #373737;
            background-color: #ede6de;
            text-align: justify;
        }
        .section-media,
        .section-media a {
            color: #373737;
            background-color: #ede6df;
            text-align: justify;
        }
        .section-mentor,
        .section-mentor a {
            color: #373737;
            background-color: #ede6dg;
            text-align: justify;
        }        
        .logo {
            color: #f4511e;
            font-size: 200px;
        }
        
        .thumbnail {
            padding: 0 0 15px 0;
            border: none;
            border-radius: 0;
        }
        
        .thumbnail2 {
            width: 60px;
            height: auto;
            margin-bottom: 10px;
        }
        
        .carousel-control.right,
        .carousel-control.left {
            background-image: none;
            color: #f4511e;
        }
        
        .carousel-indicators li {
            border-color: #f4511e;
        }
        
        .carousel-indicators li.active {
            background-color: #f4511e;
        }
        
        .item h4 {
            font-size: 19px;
            line-height: 1.375em;
            font-weight: 400;
            font-style: italic;
            margin: 70px 0;
        }
        
        .item span {
            font-style: normal;
        }
        
        .panel {
            border: 1px solid #f4511e;
            border-radius: 0 !important;
            transition: box-shadow 0.5s;
        }
        
        .panel:hover {
            box-shadow: 5px 0px 40px rgba(0, 0, 0, .2);
        }
        
        .panel-footer .btn:hover {
            border: 1px solid #f4511e;
            background-color: #fff !important;
            color: #f4511e;
        }
        
        .panel-heading {
            color: #fff !important;
            background-color: #f4511e !important;
            padding: 25px;
            border-bottom: 1px solid transparent;
            border-top-left-radius: 0px;
            border-top-right-radius: 0px;
            border-bottom-left-radius: 0px;
            border-bottom-right-radius: 0px;
        }
        
        .panel-footer {
            background-color: white !important;
        }
        
        .panel-footer h3 {
            font-size: 32px;
            font-weight: 600;
            margin-bottom: 30px;
        }
        
        .panel-footer h4 {
            font-size: 14px;
        }
        
        .panel-footer .btn {
            margin: 15px 0;
        }
        
        .navbar {
            margin-bottom: 0;
            z-index: 9999;
            border: 0;
            font-size: 12px !important;
            line-height: 1.42857143 !important;
            letter-spacing: 4px;
            border-radius: 0;
            font-family: Montserrat, sans-serif;
        }
        
        .navbar li a,
        .navbar .navbar-brand {
            font-family: Montserrat, sans-serif;
        }
        
        .navbar-nav li a:hover,
        .navbar-nav li.active a {
            background-color: #C0B283 !important;
            color: #FFFFFF !important;
            transition: 0.3s;
        }
        
        .navbar-default .navbar-toggle {
            border-color: transparent;
            color: #fff !important;
        }
        
        footer {
            background-color: #ffffff;
        }
        
        footer .glyphicon {
            font-size: 20px;
            margin-bottom: 20px;
            color: #C0B283;
        }
		
		.glyphicon {
            font-size: 20px;
            margin-bottom: 20px;
            color: #373737;
        }
        
        .slideanim {
            visibility: hidden;
        }
        
        .slide {
            animation-name: slide;
            -webkit-animation-name: slide;
            animation-duration: 1s;
            -webkit-animation-duration: 1s;
            visibility: visible;
        }
        
        @keyframes slide {
            0% {
                opacity: 0;
                transform: translateY(70%);
            }
            100% {
                opacity: 1;
                transform: translateY(0%);
            }
        }
        
        @-webkit-keyframes slide {
            0% {
                opacity: 0;
                -webkit-transform: translateY(70%);
            }
            100% {
                opacity: 1;
                -webkit-transform: translateY(0%);
            }
        }
        
        @media screen and (max-width: 768px) {
            .col-sm-4 {
                text-align: center;
                margin: 25px 0;
            }
            .btn-lg {
                width: 100%;
                margin-bottom: 35px;
            }
        }
        
        @media screen and (max-width: 480px) {
            .logo {
                font-size: 150px;
            }
        }
        
        .external-link-icon {
            float: left;
            margin: 0pt 5pt;
            width: 50pt;
            height: 50pt;
            opacity: 1;
        }
        
        .external-link-icon img {
            transition: 0.3s;
            border-radius: 50%;
        }
        
        .external-link-icon img:hover {
            background-color: #C0B283;
            transition: 0.3s;
            border-radius: 50%;
        }
        
        .external-link-container {
            text-align: center;
            width: 100%;
            height: 60pt;
        }
        
        .external-link-center-wrapper {
            margin: 20px auto auto;
            width: 300pt;
            height: 60pt;
        }
        
        .button {
            background-color: #373737;
            border: none;
            color: white;
            padding: 8px 32px;
            text-align: center;
            font-size: 18px;
            margin: 4px 2px;
            transition: 0.3s;
            display: inline-block;
            text-decoration: none;
            cursor: pointer;
            border-radius: 5px;
        }
        
        .button:hover {
            background-color: #C0B283;
            color: #ffffff;
        }
    </style>
</head>

<body id="myPage" data-spy="scroll" data-target=".navbar" data-offset="60" class="section-default">

    <nav class="navbar navbar-default navbar-fixed-top section-navbar">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#myPage">Manish Bhattarai</a>
            </div>
            <div class="collapse navbar-collapse" id="myNavbar">
                <ul class="nav navbar-nav navbar-right">
                    <li><a href="#about">ABOUT</a></li>
                    <li><a href="#recent">NEWS</a></li>
                    <li><a href="#research">RESEARCH</a></li>
                    <li><a href="#publications">PUBLICATIONS</a></li>
                    <li><a href="#media">MEDIA COVERAGES</a></li>
                    <li><a href="#mentor">MENTORING</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="data/manish_cv.pdf" onclick="getOutboundLink('data/manish_cv.pdf'); return false;" target="_blank">CV</a></li>
                    </h1>
            </div>
        </div>
    </nav>

    <div class="jumbotron text-center">
        <h1>Manish Bhattarai<br>
  	<div class = "external-link-container">
	  <div class="external-link-center-wrapper">
	    <div class = "external-link-icon">
	    	<a href="https://www.linkedin.com/in/ceodspspectrum/" onclick="getOutboundLink('https://www.linkedin.com/in/ceodspspectrum/'); return false;" target="_blank">
            	<span><img border="0" alt="Manish Bhattarai Linkedin" src="images/LI-Logo.jpg"></img></span>
            </a>
	    </div>
	    <div class = "external-link-icon">
	    	<a href="https://scholar.google.com/citations?user=ilrNKq0AAAAJ&hl=en" onclick="getOutboundLink('https://scholar.google.com/citations?user=ilrNKq0AAAAJ&hl=en'); return false;" target="_blank">
            	<span><img border="0" alt="Manish Bhattarai Google Scholar" src="images/GS-logo.jpg"></img></span>
            </a>
	    </div>
		<div class = "external-link-icon">
	    	<a href="https://github.com/ceodspspectrum" onclick="getOutboundLink('https://github.com/ceodspspectrum'); return false;" target="_blank">
				<span><img border="0" alt="Tyler Hayes GitHub" src="images/github-logo.jpg"></img></span>
            </a>
	    </div>
		<div class = "external-link-icon">
	    	<a href="https://twitter.com/ceodspspectrum" onclick="getOutboundLink('https://twitter.com/ceodspspectrum'); return false;" target="_blank">
				<span><img border="0" alt="Manish Bhattarai Twitter" src="images/twitter-logo.png"></img></span>
            </a>
	    </div>
	    <div class = "external-link-icon">
	    	<a href="" rel="nofollow" onclick="this.href='mailto:' + 'ceodspspectrum' + '@' + 'lanl.gov'" target="_blank">
            	<span><img border="0" alt="Manish Bhattarai Contact" src="images/mail-logo.png"></img></span>
            </a>
	    </div>
	  </div>
	</div>
</div>

  </form>

<!-- Container (About Section) -->
<div id="about" class="container-fluid section-about-me">
  <div class="row">
    <h2>About Me</h2>
    <div class="col-sm-2 col-sm-offset-3">
      <span><img src="images/bhattarai.jpg" alt="Manish Bhattarai" class="img-responsive" style="border-radius: 25px"></span>
	</div>
    <div class="col-sm-4">
      <h4> I am a Postdoc Research associate in the <a href="https://www.lanl.gov/org/ddste/aldsc/theoretical/fluid-dynamics-solid-mechanics/index.php" onclick="getOutboundLink('https://www.lanl.gov/org/ddste/aldsc/theoretical/fluid-dynamics-solid-mechanics/index.php'); return false;">Theoretical division </a> at the <a href="https://www.lanl.gov/" onclick="getOutboundLink('https://www.lanl.gov/'); return false;">Los Alamos National Laboratory</a> in Los Alamos, NM. 
         At LANL, I am part of the tensor factorizations group. I graduated with a Ph.D. and an M.S. from the Department of Electrical and Computer &amp; Engineering at <a href=" http://ece.unm.edu/">The University of New Mexico</a> in 2017 and 2020 respectively. At UNM, I worked under my advisor, <a href=" https://ece.unm.edu/faculty-staff/electrical-and-computer/manel-martinez-ramon.html">Dr. Manel Martinez-Ramon</a> on the application of deep learning for firefighting. My current research interests include: <i><b>machine learning</b></i>,<i><b> computer vision</b></i>, <i><b>deep learning</b></i>, <i><b>tensor factorizations</b></i> and <i><b>high performance computing</b></i>.

<p> I am passionate about  various deep learning techniques for data inferences and reasoning. I have extensively worked on developing HPC empowered ML algorithms for mining big data. My current works are on distributed Matrix and Tensor factorization. I am also interested in accelerating deep learning frameworks with Tensor factorization. 
</p>

	  </h4>
    </div>
  </div>
</div>

<!-- Container (News) -->
<div id="recent" class="container-fluid section-recent-news">
  <div class="row">
    <div class="col-sm-8 col-sm-offset-2">
      <h2>News</h2>
	  
		<!-- Recent News -->
		<!-- <h4><strong>Sep 2020:</strong> <span class="newflag">NEW!</span> Our paper <a href="https://doi.org/10.1371/journal.pone.0238302" onclick="getOutboundLink('https://doi.org/10.1371/journal.pone.0238302'); return false;">"Are Open Set Classification Methods Effective on Large-Scale Datasets?"</a> was published in PLoS ONE!</h4>-->
		<h4><strong>Jan 2021:</strong> <span class="newflag">NEW!</span> Joined as a Postdoc Research associate in the <a href="https://www.lanl.gov/org/ddste/aldsc/theoretical/fluid-dynamics-solid-mechanics/index.php" onclick="getOutboundLink('https://www.lanl.gov/org/ddste/aldsc/theoretical/fluid-dynamics-solid-mechanics/index.php'); return false;">Theoretical division </a> at the <a href="https://www.lanl.gov/" onclick="getOutboundLink('https://www.lanl.gov/'); return false;">Los Alamos National Laboratory</a> in Los Alamos,NM.  </h4>
		<h4><strong>Dec 2020:</strong> Obtained Phd. with distinction in Electrical Engineering from UNM.</h4>

		<h4><strong>Dec 2020:</strong> Presented our paper <a href="https://arxiv.org/abs/2009.10679" onclick="getOutboundLink('https://arxiv.org/abs/2009.10679'); return false;">"An embedded deep learning system for augmented reality in firefighting applications"</a> at <a href="https://www.icmla-conference.org/icmla20/" onclick="getOutboundLink('https://www.icmla-conference.org/icmla20/'); return false;"> IEEE ICMLA.</a> </h4>
        <h4><strong>Nov 2020:</strong> Our paper <a href="https://arxiv.org/abs/2011.06450" onclick="getOutboundLink('https://arxiv.org/abs/2011.06450'); return false;">"A deep Q-Learning based Path Planning and Navigation System for Firefighting Environments"</a> was accepted to the <a href="http://www.icaart.org/" onclick="getOutboundLink('http://www.icaart.org/'); return false;"> ICAART 2021.</a> </h4>

		<h4><strong>Sep 2020:</strong> Our paper <a href="https://arxiv.org/abs/2009.10679" onclick="getOutboundLink('https://arxiv.org/abs/2009.10679'); return false;">"An embedded deep learning system for augmented reality in firefighting applications"</a> was accepted to the <a href="https://www.icmla-conference.org/icmla20/" onclick="getOutboundLink('https://www.icmla-conference.org/icmla20/'); return false;"> IEEE ICMLA.</a> </h4>
        <h4><strong>Sep 2020:</strong> Our paper "Semantic Nonnegative Matrix Factorization with Automatic Model Determination for Topic Modeling" was accepted to the <a href="https://www.icmla-conference.org/icmla20/" onclick="getOutboundLink('https://www.icmla-conference.org/icmla20/'); return false;"> IEEE ICMLA.</a> </h4>

        <h4><strong>Sep 2020:</strong> Presented our paper <a href="https://ieeexplore.ieee.org/abstract/document/9286234" onclick="getOutboundLink('https://ieeexplore.ieee.org/abstract/document/9286234'); return false;">"Distributed Non-Negative Tensor Train Decomposition"</a> at <a href="http://www.ieee-hpec.org/" onclick="getOutboundLink('http://www.ieee-hpec.org/'); return false;"> IEEE HPEC.</a> </h4>

        <h4><strong>Aug 2020:</strong>Our paper <a href="https://ieeexplore.ieee.org/abstract/document/9286234" onclick="getOutboundLink('https://ieeexplore.ieee.org/abstract/document/9286234'); return false;">"Distributed Non-Negative Tensor Train Decomposition"</a> was accepted at <a href="http://www.ieee-hpec.org/" onclick="getOutboundLink('http://www.ieee-hpec.org/'); return false;"> IEEE HPEC.</a> </h4>

     <h4><strong>Jun 2020:</strong> Presented our paper <a href="https://ieeexplore.ieee.org/document/9150858" onclick="getOutboundLink('https://ieeexplore.ieee.org/document/9150858'); return false;">"Diagram Image Retrieval using Sketch-Based Deep Learning and Transfer Learning"</a> at <a href="https://cvpr-dira.lipingyang.org/" onclick="getOutboundLink('https://cvpr-dira.lipingyang.org/'); return false;"> IEEE CVPR DIRA Workshop.</a> </h4>

        <h4><strong>Apr 2020:</strong> Our paper <a href="https://ieeexplore.ieee.org/document/9150858" onclick="getOutboundLink('https://ieeexplore.ieee.org/document/9150858'); return false;">"Diagram Image Retrieval using Sketch-Based Deep Learning and Transfer Learning"</a> was accepted at <a href="https://cvpr-dira.lipingyang.org/" onclick="getOutboundLink('https://cvpr-dira.lipingyang.org/'); return false;"> IEEE CVPR DIRA Workshop.</a> </h4>

        <h4><strong>Apr 2020:</strong> Our paper <a href="https://ieeexplore.ieee.org/document/9151092" onclick="getOutboundLink('https://ieeexplore.ieee.org/document/9151092'); return false;">"Diagram Image Retrieval using Sketch-Based Deep Learning and Transfer Learning"</a> was accepted at <a href="https://cvpr-dira.lipingyang.org/" onclick="getOutboundLink('https://cvpr-dira.lipingyang.org/'); return false;"> IEEE CVPR DIRA Workshop.</a> </h4>


		
    </div>
	

    </div>
  </div>
</div>

<!-- Container (Research Section) -->
<div id="research" class="container-fluid section-research">
	<div class="row">
		<h2>Research</h2>
	</div>
	
	<!-- PLOS ONE 2020 -->
	<div class="row">
		<div class="col-sm-8 col-sm-offset-2">
			<h3><strong>ICAART 2021</strong>: A deep Q-Learning based Path Planning and Navigation System for Firefighting Environments</h3>
			<h4> <strong>Manish Bhattarai</strong>, Manel Martinez-Ramon</h4>
			<h3>
				<a href="https://arxiv.org/abs/2011.06450" onclick="getOutboundLink('https://arxiv.org/abs/2011.06450'); return false;" target="_blank"><button class="button">arXiv</button></a>

			</h3>
		</div>
	</div>

    <div class="row">
		<div class="col-sm-2 col-sm-offset-2">
			<img src="images/dqn.png" alt="arXiv 2020" class="img-responsive"></img>
		</div>
		<div class="col-sm-6">
			<h5 class="h5-small"><p>Live fire creates a dynamic, rapidly changing environment that presents a worthy challenge for deep learning and artificial intelligence methodologies to assist firefighters with scene comprehension in maintaining their situational awareness, tracking and relay of important features necessary for key decisions as they tackle these catastrophic events. We propose a deep Q-learning based agent who is immune to stress induced disorientation and anxiety and thus able to make clear decisions for navigation based on the observed and stored facts in live fire environments. As a proof of concept, we imitate structural fire in a gaming engine called Unreal Engine which enables the interaction of the agent with the environment. The agent is trained with a deep Q-learning algorithm based on a set of rewards and penalties as per its actions on the environment. We exploit experience replay to accelerate the learning process and augment the learning of the agent with human-derived experiences. The agent trained under this deep Q-learning approach outperforms agents trained through alternative path planning systems and demonstrates this methodology as a promising foundation on which to build a path planning navigation assistant capable of safely guiding fire fighters through live fire environments. </p></h5>
		</div>
    </div>
	
	<!-- BMVC 2020 -->
	<div class="row">
		<div class="col-sm-8 col-sm-offset-2">
			<h3><strong>IEEE ICMLA 2020</strong>: An embedded deep learning system for augmented reality in firefighting applications</h3>
			<h4><strong>Manish Bhattarai</strong>, Aura Rose Jensen-Curtis, Manel MartíNez-Ramón</h4>
			<h3>
				<a href="https://arxiv.org/abs/2009.10679" onclick="getOutboundLink('https://arxiv.org/abs/2009.10679'); return false;" target="_blank"><button class="button">arXiv</button></a>
				<a href="https://youtu.be/PI4JQlvQ2ho" onclick="getOutboundLink('https://youtu.be/PI4JQlvQ2ho'); return false;" target="_blank"><button class="button">Video</button></a>
			</h3>
		</div>
	</div>

    <div class="row">
		<div class="col-sm-2 col-sm-offset-2">
			<img src="images/augmented.png" alt="BMVC 2020" class="img-responsive"></img>
		</div>
		<div class="col-sm-6">
			<h5 class="h5-small"><p>Firefighting is a dynamic activity, in which numerous operations occur simultaneously. Maintaining situational awareness (i.e., knowledge of current conditions and activities at the scene) is critical to the accurate decision-making necessary for the safe and successful navigation of a fire environment by firefighters. Conversely, the disorientation caused by hazards such as smoke and extreme heat can lead to injury or even fatality. This research implements recent advancements in technology such as deep learning, point cloud and thermal imaging, and augmented reality platforms to improve a firefighter's situational awareness and scene navigation through improved interpretation of that scene. We have designed and built a prototype embedded system that can leverage data streamed from cameras built into a firefighter's personal protective equipment (PPE) to capture thermal, RGB color, and depth imagery and then deploy already developed deep learning models to analyze the input data in real time. The embedded system analyzes and returns the processed images via wireless streaming, where they can be viewed remotely and relayed back to the firefighter using an augmented reality platform that visualizes the results of the analyzed inputs and draws the firefighter's attention to objects of interest, such as doors and windows otherwise invisible through smoke and flames. </p></h5>
		</div>
    </div>

	<!-- ECCVW 2020 -->
	<div class="row">
		<div class="col-sm-8 col-sm-offset-2">
			<h3><strong>IEEE ICMLA 2020</strong>: Semantic Nonnegative Matrix Factorization with Automatic Model Determination for Topic Modeling </h3>
			<h4>Raviteja Vangara , Erik Skau , Gopinath Chennupati , Hirsto Djidjev , Thomas Tierney , James Smith , <strong>Manish Bhattarai</strong> , Valentin Stanev , Boian Alexandrov </h4>

		</div>
	</div>

    <div class="row">
		<div class="col-sm-2 col-sm-offset-2">
			<img src="images/semnmf.png" alt="HPEC 2020" class="img-responsive"></img>
		</div>
		<div class="col-sm-6">
			<h5 class="h5-small"><p>Non-negative Matrix Factorization (NMF) models the topics of a text corpus by decomposing the matrix of term frequency--inverse document frequency (TF-IDF) representation, X, into two low-rank non-negative matrices: W, representing the topics and H, mapping the documents onto space of topics. One challenge, common to all topic models, is the determination of the number of latent topics (aka model determination). Determining the correct number of topics is important: underestimating the number of topics results in a poor topic separation, under-fitting, while overestimating leads to noisy topics, over-fitting. Here, we introduce SeNMFk, a semantic-assisted NMF-based topic modeling method, which incorporates semantic correlations in NMF by using a word-context matrix, and employs a method for determination of the number of latent topics. SeNMFk first creates a random ensemble of matrices based on the initial TF-IDF matrix and a word-context matrix, and then applies a coupled factorization to acquire sets of stable coherent topics that are robust to noise. The latent dimension is determined based on the stability of these topics. We show that SeNMFk accurately determines the number of high-quality topics in benchmark text corpora, which leads to an accurate document clustering.</p></h5>
		</div>
    </div>

	<!-- ECCV 2020 -->
	<div class="row">
		<div class="col-sm-8 col-sm-offset-2">
			<h3><strong>IEEE HPEC 2020</strong>: Distributed Non-Negative Tensor Train Decomposition </h3>
			<h4> <strong>Manish Bhattarai</strong>, Gopinath Chennupati, Erik Skau, Raviteja Vangara, Hristo Djidjev, Boian S. Alexandrov</h4>
			
			<h3>
				<a href="https://arxiv.org/abs/2008.01340" onclick="getOutboundLink('https://arxiv.org/abs/2008.01340'); return false;" target="_blank"><button class="button">arXiv</button></a>
                <a href="https://ieeexplore.ieee.org/document/9286234" onclick="getOutboundLink('https://ieeexplore.ieee.org/document/9286234'); return false;" target="_blank"><button class="button">IEEE Explore</button></a>
    
			</h3>
		</div>
	</div>

    <div class="row">
		<div class="col-sm-2 col-sm-offset-2">
			<img src="images/distntt.png" alt="arXiv 2019" class="img-responsive"></img>
		</div>
		<div class="col-sm-6">
			<h5 class="h5-small"><p>The era of exascale computing opens new venues for innovations and discoveries in many scientific, engineering, and commercial fields. However, with the exaflops also come the extra-large high-dimensional data generated by highperformance computing. High-dimensional data is presented as multidimensional arrays, aka tensors. The presence of latent (not directly observable) structures in the tensor allows a unique representation and compression of the data by classical tensor factorization techniques. However, the classical tensor methods are not always stable or they can be exponential in their memory requirements, which makes them not suitable for high-dimensional tensors. Tensor train (TT) is a state-of-the-art tensor network introduced for factorization of high-dimensional tensors. TT transforms the initial high-dimensional tensor in a network of three-dimensional tensors that requires only a linear storage. Many real-world data, such as, density, temperature, population, probability, etc., are non-negative and for an easy interpretation, the algorithms preserving non-negativity are preferred. Here, we introduce a distributed non-negative tensor-train and demonstrate its scalability and the compression on synthetic and realworld big datasets.</p></h5>
		</div>
    </div>

	<!-- CVPRW 2020 -->
	<div class="row">
		<div class="col-sm-8 col-sm-offset-2">
			<h3><strong>CVPRW 2020</strong>: Diagram Image Retrieval using Sketch-Based Deep Learning and Transfer Learning</h3>
	
			<h4><strong>Manish Bhattarai</strong>, Diane Oyen, Juan Castorena, Liping Yang, Brendt Wohlberg</h4>
			<h3>
				<a href="https://arxiv.org/abs/2004.10780" onclick="getOutboundLink('https://arxiv.org/abs/2004.10780'); return false;" target="_blank"><button class="button">arXiv</button></a>
				<a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w8/Bhattarai_Diagram_Image_Retrieval_Using_Sketch-Based_Deep_Learning_and_Transfer_Learning_CVPRW_2020_paper.pdf" onclick="getOutboundLink('https://openaccess.thecvf.com/content_CVPRW_2020/papers/w8/Bhattarai_Diagram_Image_Retrieval_Using_Sketch-Based_Deep_Learning_and_Transfer_Learning_CVPRW_2020_paper.pdf'); return false;" target="_blank"><button class="button">Paper</button></a>

				<a href="https://www.youtube.com/watch?v=J_EF__ucluw" onclick="getOutboundLink('https://www.youtube.com/watch?v=J_EF__ucluw'); return false;" target="_blank"><button class="button">Video</button></a>
			</h3>
		</div>
	</div>
	
    <div class="row">
		<div class="col-sm-2 col-sm-offset-2">
			<img src="images/dira.png" alt="arXiv 2019" class="img-responsive"></img>
		</div>
		<div class="col-sm-6">
			<h5 class="h5-small"><p>Resolution of the complex problem of image retrieval for diagram images has yet to be reached. Deep learning methods continue to excel in the fields of object detection and image classification applied to natural imagery. However, the application of such methodologies applied to binary imagery remains limited due to lack of crucial features such as textures, color and intensity information. This paper presents a deep learning based method for image-based search for binary patent images by taking advantage of existing large natural image repositories for image search and sketch-based methods.(Sketches are not identical to diagrams, but they do share some characteristics; for example, they both are gray scale (binary), composed of contours, and lacking in texture are key features for both imagery types.) We begin by using deep learning to generate sketches from natural images for image retrieval and then train a second deep learning model on the sketches. We then use our small set of manually labeled patent diagram images via transfer learning to adapt the image search from sketches of natural images to diagrams. Our experiment results show the effectiveness of deep learning with transfer learning for detecting near-identical copies in patent images and querying similar images based on content.</p></h5>
		</div>
    </div>
	
	<!-- CVPRW 2020 -->
	<div class="row">
		<div class="col-sm-8 col-sm-offset-2">
			<h3><strong>CVPRW 2020</strong>: Learning Spatial Relationships Between Samples of Patent Image Shapes</h3>
			<h4>Juan Castorena, <strong>Manish Bhattarai</strong>, Diane Oyen</h4>
		
			<h3>
				<a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w8/Castorena_Learning_Spatial_Relationships_Between_Samples_of_Patent_Image_Shapes_CVPRW_2020_paper.html" onclick="getOutboundLink('https://openaccess.thecvf.com/content_CVPRW_2020/html/w8/Castorena_Learning_Spatial_Relationships_Between_Samples_of_Patent_Image_Shapes_CVPRW_2020_paper.html'); return false;" target="_blank"><button class="button">Paper</button></a>
			

				<a href="https://www.youtube.com/watch?v=KkU-vxjVEeA" onclick="getOutboundLink('https://www.youtube.com/watch?v=KkU-vxjVEeA'); return false;" target="_blank"><button class="button"> Talk</button></a>

			</h3>
		</div>
	</div>

    <div class="row">
		<div class="col-sm-2 col-sm-offset-2">
			<img src="images/dynamic.png" alt="arXiv 2019" class="img-responsive"></img>
		</div>
		<div class="col-sm-6">
			<h5 class="h5-small"><p> Binary image based classification and retrieval of documents of an intellectual nature is a very challenging problem. Variations in the binary image generation mechanisms which are subject to the document artisan designer including drawing style, view-point, inclusion of multiple image components are plausible causes for increasing the complexity of the problem. In this work, we propose a method suitable to binary images which bridges some of the successes of deep learning (DL) to alleviate the problems introduced by the aforementioned variations. The method consists on extracting the shape of interest from the binary image and applying a non-Euclidean geometric neural-net architecture to learn the local and global spatial relationships of the shape. Empirical results show that our method is in some sense invariant to the image generation mechanism variations and achieves results outperforming existing methods in a patent image dataset benchmark.
</p></h5>
		</div>
    </div>
	
	<!-- arXiv Preprint 2020 -->
	<div class="row">
		<div class="col-sm-8 col-sm-offset-2">
			<h3><strong>IEEE Acess 2020</strong>: A Deep Learning Framework for Detection of Targets in Thermal Images to Improve Firefighting </h3>
			<h4> <strong>Manish Bhattarai</strong>, Manel Martinez-Ramon</h4>
			<h3>
				<a href="https://ieeexplore.ieee.org/abstract/document/9090877" onclick="getOutboundLink('https://ieeexplore.ieee.org/abstract/document/9090877'); return false;" target="_blank"><button class="button">IEEE Explore</button></a>

                <a href="https://arxiv.org/abs/1910.03617" onclick="getOutboundLink('https://arxiv.org/abs/1910.03617'); return false;" target="_blank"><button class="button">arXiv</button></a>
                			</h3>
		</div>
	</div>

    <div class="row">
		<div class="col-sm-2 col-sm-offset-2">
			<img src="images/access.png" alt="IEEE ACCESS" class="img-responsive"></img>
		</div>
		<div class="col-sm-6">
			<h5 class="h5-small"><p>Intelligent detection and processing capabilities can be instrumental in improving the safety, efficiency, and successful completion of rescue missions conducted by firefighters in emergency first response settings. The objective of this research is to create an automated system that is capable of real-time, intelligent object detection and recognition and facilitates the improved situational awareness of firefighters during an emergency response. We have explored state-of-the-art machine/deep learning techniques to achieve this objective. The goal of this work is to enhance the situational awareness of firefighters by effectively exploiting the infrared video that is actively recorded by firefighters on the scene. To accomplish this, we use a trained deep Convolutional Neural Network (CNN) system to classify and identify objects of interest from thermal imagery in real-time. In the midst of those critical circumstances created by a structure fire, this system is able to accurately inform the decision-making process of firefighters with up-to-date scene information by extracting, processing, and analyzing crucial information. Utilizing the new information produced by the framework, firefighters are able to make more informed inferences about the circumstances for their safe navigation through such hazardous and potentially catastrophic environments.</p></h5>
		</div>
    </div>

    <div class="row">
        <div class="col-sm-8 col-sm-offset-2">
            <h3><strong>Journal of Neuroscience Methods 2020</strong>: Deep residual learning for neuroimaging: An application to predict progression to alzheimer’s disease </h3>
            <h4> Anees Abrol, <strong> Manish Bhattarai</strong>, Alex Fedorov, Yuhui Du, Sergey Plis, Vince Calhoun </h4>
            <h3>
                <a href="https://www.sciencedirect.com/science/article/pii/S0165027020301242" onclick="getOutboundLink('https://www.sciencedirect.com/science/article/pii/S0165027020301242'); return false;" target="_blank"><button class="button">Science direct</button></a>

                                          </h3>
        </div>
    </div>

    <div class="row">
        <div class="col-sm-2 col-sm-offset-2">
            <img src="images/bio.png" alt="Journal of Neuroscience Methods" class="img-responsive"></img>
        </div>
        <div class="col-sm-6">
            <h5 class="h5-small"><p>Background:The unparalleled performance of deep learning approaches in generic image processing has mo-tivated its extension to neuroimaging data. These approaches learn abstract neuroanatomical and functionalbrain alterations that could enable exceptional performance in classification of brain disorders, predicting dis-ease progression, and localizing brain abnormalities.
                New Method:This work investigates the suitability of a modified form of deep residual neural networks (ResNet)for studying neuroimaging data in the specific application of predicting progression from mild cognitive im-pairment (MCI) to Alzheimer’s disease (AD). Prediction was conductedfirst by training the deep models usingMCI individuals only, followed by a domain transfer learning version that additionally trained on AD andcontrols. We also demonstrate a network occlusion based method to localize abnormalities.
                Results:The implemented framework captured non-linear features that successfully predicted AD progressionand also conformed to the spectrum of various clinical scores. In a repeated cross-validated setup, the learntpredictive models showed highly similar peak activations that corresponded to previous AD reports.Comparison with existing 
                methods:The implemented architecture achieved a significant performance improve-ment over the classical support vector machine and the stacked autoencoder frameworks (p< 0.005), nu-merically better than state-of-the-art performance using sMRI data alone (> 7% than the second-best performingmethod) and within 1% of the state-of-the-art performance considering learning using multiple neuroimagingmodalities as well.
            Conclusions:The explored frameworks reflected the high potential of deep learning architectures in learningsubtle predictive features and utility in critical applications such as predicting and understanding disease pro-gression</p></h5>
        </div>
    </div>
    <!-- arXiv Preprint 2020 -->
    <div class="row">
        <div class="col-sm-8 col-sm-offset-2">
            <h3><strong>arxiv 2020</strong>: A Novel Indoor Positioning System for unprepared firefighting scenarios </h3>
            <h4> Vamsi Karthik Vadlamani, <strong>Manish Bhattarai</strong>, Meenu Ajith, Manel Martınez-Ramon</h4>
            <h3>
                <a href="https://arxiv.org/abs/2008.01344" onclick="getOutboundLink('https://arxiv.org/abs/2008.01344'); return false;" target="_blank"><button class="button">arXiv</button></a>

        
        </div>
    </div>

    <div class="row">
        <div class="col-sm-2 col-sm-offset-2">
            <img src="images/planning.png" alt="IEEE ACCESS" class="img-responsive"></img>
        </div>
        <div class="col-sm-6">
            <h5 class="h5-small"><p>Situational awareness and Indoor location tracking for firefighters is one of the tasks with paramount importance in search and rescue operations. For Indoor Positioning systems (IPS), GPS is not the best possible solution. There are few other techniques like dead reckoning, Wifi and bluetooth based triangulation, Structure from Motion (SFM) based scene reconstruction for Indoor positioning system. However due to high temperatures, the rapidly changing environment of fires, and low parallax in the thermal images, these techniques are not suitable for relaying the necessary information in a fire fighting environment needed to increase situational awareness in real time. In fire fighting environments, thermal imaging cameras are used due to smoke and low visibility hence obtaining relative orientation from the vanishing point estimation is very difficult. The following technique that is the content of this research implements a novel optical flow based video compass for orientation estimation and fused IMU data based activity recognition for IPS. This technique helps first responders to go into unprepared, unknown environments and still maintain situational awareness like the orientation and, position of the victim fire fighters. </p></h5>
        </div>
    </div>



<!-- Container (Publications) -->
<div id="publications" class="container-fluid section-publications">
	<div class="row">
		<div class="col-sm-8 col-sm-offset-2">
			<h2>Publications</h2>
			<h4>Conferences</h4>
			<h5><ul style="list-style-type:circle">
			<li> <strong>Bhattarai, M.</strong>, Oyen, D., Castorena, J., Yang, L., & Wohlberg, B. (2020).  <a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w8/Bhattarai_Diagram_Image_Retrieval_Using_Sketch-Based_Deep_Learning_and_Transfer_Learning_CVPRW_2020_paper.html" onclick="getOutboundLink('https://openaccess.thecvf.com/content_CVPRW_2020/html/w8/Bhattarai_Diagram_Image_Retrieval_Using_Sketch-Based_Deep_Learning_and_Transfer_Learning_CVPRW_2020_paper.html'); return false;">Diagram Image Retrieval
using Sketch-Based Deep Learning and Transfer Learning.</a> In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition Workshops (pp. 174-175).</li>
			<li>Castorena, J.,<strong> Bhattarai, M.</strong>, & Oyen, D. (2020).  <a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w8/Castorena_Learning_Spatial_Relationships_Between_Samples_of_Patent_Image_Shapes_CVPRW_2020_paper.html" onclick="getOutboundLink('https://openaccess.thecvf.com/content_CVPRW_2020/html/w8/Castorena_Learning_Spatial_Relationships_Between_Samples_of_Patent_Image_Shapes_CVPRW_2020_paper.html'); return false;">Learning Spatial Relationships Between Samples of
Patent Image Shapes. </a> In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition Workshops (pp. 172-173).</li>
			<li><strong>Bhattarai, M.</strong>, Chennupati, G., Skau, E., Vangara, R., Djidjev, H., & Alexandrov, B. S. (2020, September). <a href="https://ieeexplore.ieee.org/abstract/document/9286234" onclick="getOutboundLink('https://ieeexplore.ieee.org/abstract/document/9286234'); return false;">Distributed Non-Negative Tensor Train Decomposition.</a>  In 2020 IEEE High Performance Extreme Computing Conference (HPEC) (pp. 1-10). IEEE.</li>


				<li><strong>Bhattarai, M.</strong>, & Martinez, M.(2021) <a href="https://arxiv.org/abs/2011.06450" onclick="getOutboundLink('https://arxiv.org/abs/2011.06450'); return false;">A deep Q-learning based path planning and navigation system for
firefighting environments.</a> In  ICAART 2021</li>

                <li><strong>Bhattarai ,M.</strong>, Curtis,A.,& Martinez, M.(2020) <a href="https://arxiv.org/abs/2011.06450" onclick="getOutboundLink('https://arxiv.org/abs/2011.06450'); return false;">An embedded deep learning system for augmented reality in
firefighting applications.</a> In  ICMLA 2020</li>


				<li><strong>Bhattarai, M.</strong> , Ghasemi, J., Fiorante, G. R., Zarkesh-Ha, P., Krishna, S., & Hayat, M. M. (2016,
October).<a href="https://ieeexplore.ieee.org/abstract/document/7831136" onclick="getOutboundLink('https://ieeexplore.ieee.org/abstract/document/7831136'); return false;"> Intelligent bias-selection method for computational imaging on a CMOS imager.</a> In Photonics
Conference (IPC), 2016 IEEE (pp. 244-245). IEEE.
</li>
				<li>Vangara,R.,Skau,E.,Chennupati,G., Djidjev,H., Tierney,T., Smith,J.,<strong> Bhattarai, M.</strong> , Stanev,V., &
Alexandrov,B. 2020. Semantic Nonnegative Matrix Factorization with Automatic Model Determination
for Topic Modeling. ICMLA 2020.</li>

			</ul></h5>

			<h4>Journals</h4>
			<h5><ul style="list-style-type:circle">
			<li><strong>Bhattarai,M. </strong>, & Martínez-Ramón,M,<a href="https://ieeexplore.ieee.org/abstract/document/9090877" onclick="getOutboundLink('https://ieeexplore.ieee.org/abstract/document/9090877'); return false;">  "A Deep Learning Framework for Detection of Targets in Thermal
Images to Improve Firefighting," </a> in IEEE Access, doi: 10.1109/ACCESS.2020.2993767.</li>

            <li> Abrol, A., <strong>Bhattarai,M. </strong>, Fedorov, A., Du, Y., Plis, S., Calhoun, V., & Alzheimer’s Disease Neuroimaging
              Initiative. (2020).<a href="https://www.sciencedirect.com/science/article/pii/S0165027020301242" onclick="getOutboundLink('https://www.sciencedirect.com/science/article/pii/S0165027020301242'); return false;"> Deep residual learning for neuroimaging: An application to predict progression to
        alzheimer’s disease.  </a> In Journal of Neuroscience Methods, 108701.</li>
            <li> Ghasemi, J., <strong>Bhattarai,M. </strong> , Fiorante, G. R., Zarkesh-Ha, P., Krishna, S., & Hayat, M. M. (2017). <a href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-25-4-4076&id=360076" onclick="getOutboundLink('https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-25-4-4076&id=360076'); return false;"> 
CMOS approach to compressed-domain image acquisition.</a> Optics Express, 25(4), 4076-4096</li>
            <li>Vadlamani, V. K.,  <strong>Bhattarai,M. </strong> , Ajith, M., & Martınez-Ramon, M. (2020).<a href="https://arxiv.org/abs/2008.01344" onclick="getOutboundLink('https://arxiv.org/abs/2008.01344'); return false;">  A Novel Indoor Positioning System for unprepared firefighting scenarios. </a>arXiv preprint arXiv:2008.01344.</li>

			</ul></h5>

			<h4>Posters</h4>
			<h5><ul style="list-style-type:circle">
				<li> <strong>Bhattarai,M. </strong>, Vadlamani,K., Abrol,A., & Martinez, M. End-to-End Deep Learning Systems for
Scene Understanding, Path Planning and Navigation in Fire Fighter Teams. Shared Knowledge
Conference,2018,UNM. and state of New Mexico Legislature</li>
				<li><strong>Bhattarai,M. </strong>, & Martinez, M. End-to-End Deep Learning Systems for Scene Understanding, Path Planning
and Navigation in Fire Fighter Teams. Rocky Mountain Advanced Computing Consortium(RMAC),
2019</li>
    <li><strong>Bhattarai,M. </strong>, & Martinez, M. Smart and Connected Firefighting System Design, FDIC International,
2019</li>
    <li><strong>Bhattarai,M. </strong>, & Martinez, M. Smart and Connected Firefighting System Design, Innovate New-
Mexico, 2019</li>
    <li><strong>Bhattarai,M. </strong>, Oyen,D., Yang, L. , Wohlberg, B.,Patent Image Retrieval Using Sketch-based Deep
Learning And Transfer Learning. CODA 2020 Conference , SantaFe</li>
    <li><strong>Bhattarai,M. </strong>, Oyen,D., Yang, L. , Wohlberg, B.,Patent Image Retrieval Using Sketch-based Deep
Learning And Transfer Learning. AI and Tensor Factorization Conference,2020, SantaFe</li>
			</ul></h5>

			<h4>Thesis</h4>
			<h5><ul style="list-style-type:circle">
				<li><strong>Manish Bhattarai</strong>. <a href="https://digitalrepository.unm.edu/ece_etds/403/" onclick="getOutboundLink('https://digitalrepository.unm.edu/ece_etds/403/'); return false;">Algorithm for Computational Imaging on a Real-Time Hardware
</a>. M.S. Thesis, University of New Mexico, 2017</li>
			</ul></h5>
        </div>
    </div>

<div id="media" class="container-fluid section-media">
    <div class="row">
        <div class="col-sm-8 col-sm-offset-2">
             <h2>Media Coverages</h2>
  
           
            <h5><ul style="list-style-type:circle">
                <li><strong>UNM News</strong>. <a href="http://news.unm.edu/news/unm-researcher-develops-technology-aimed-at-preventinginjury-
and-deaths-in-a-fire" onclick="getOutboundLink('http://news.unm.edu/news/unm-researcher-develops-technology-aimed-at-preventing-injury-and-deaths-in-a-fire'); return false;">UNM researcher develops technology aimed at preventing injury and deaths in a fire
</a></li>
            </ul></h5>

            <h5><ul style="list-style-type:circle">
                <li><strong>Daily Lobo</strong>. <a href="https://www.dailylobo.com/article/2019/02/firefighting-tech-unm" onclick="getOutboundLink('https://www.dailylobo.com/article/2019/02/firefighting-tech-unm'); return false;">Student develops tech that could save firefighters' lives
</a></li>
            </ul></h5>

            <h5><ul style="list-style-type:circle">
                <li><strong>KRQE News Channel</strong>. <a href="https://www.krqe.com/news/unm-student-developing-technology-to-save-lives-of-firefighters/" onclick="getOutboundLink('https://www.krqe.com/news/unm-student-developing-technology-to-save-lives-of-firefighters/'); return false;"> UNM student developing technology to save lives of firefighters
</a></li>
            </ul></h5>

            <h5><ul style="list-style-type:circle">
                <li><strong>KOB News Channel</strong>. <a href="https://www.kob.com/new-mexico-news/unm-researcher-develops-life-savingtechnology-for-firefighters/5224015/" onclick="getOutboundLink('https://www.kob.com/new-mexico-news/unm-researcher-develops-life-savingtechnology-for-firefighters/5224015/'); return false;"> UNM researcher develops life-saving technology for firefighters
</a></li>
            </ul></h5>
            </ul></h5>

            <h5><ul style="list-style-type:circle">
                <li><strong>Fire Engineering</strong>. <a href="https://www.fireengineering.com/2019/02/07/219440/unm-researcher-firefighter-location/" onclick="getOutboundLink('https://www.fireengineering.com/2019/02/07/219440/unm-researcher-firefighter-location/'); return false;"> Researcher Develops Technology to Help Firefighters with Orientation Inside Structures
</a></li>
            </ul></h5>
            <h5>

                <ul style="list-style-type:circle">
                <li><strong>UNM CARC News</strong>. <a href="https://carc.unm.edu/research/fire-navigation-research-to-be-presented-to-nm-legislature.html" onclick="getOutboundLink('https://carc.unm.edu/research/fire-navigation-research-to-be-presented-to-nm-legislature.html'); return false;"> Fire navigation research presented at NM Legislature
</a></li>
            </ul></h5>
             <div class="col-sm-2 col-sm-offset-2">
            <img src="images/capitol.JPG" alt="Journal of Neuroscience Methods" class="img-responsive"></img>
        </div>

		</div>




<div id="mentor" class="container-fluid section-mentor">
    <div class="row">
        <div class="col-sm-8 col-sm-offset-2">
             <h2>Mentoring</h2>
  
            <p>I am really grateful to work with the following students. </p>
<table>
<thead>
<tr>
<th style="text-align:left">Name</th>
<th style="text-align:right">Institution</th>
<th style="text-align:right">Year</th>
<th style="text-align:center">Topic</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">
<a href="https://www.linkedin.com/in/william-zhao-3a0588104/" target="_blank" rel="noopener">William Zhao</a></td>
<td style="text-align:right">
<a href="https://www.berkeley.edu/" target="_blank" rel="noopener">UC Berkley</a></td>
<td style="text-align:right">2020</td>
<td style="text-align:right">Adversarial robustness of Matrix and Tensor decompositions</td>
</tr>
<tr>
<td style="text-align:left">
<a href="https://www.linkedin.com/in/aura-jensen-curtis-909b9141/" target="_blank" rel="noopener">Aura Jensen-Curtis</a></td>
<td style="text-align:left">
<a href="https://www.unm.edu/" target="_blank" rel="noopener">UNM</a></td>
<td style="text-align:right">2019&ndash;2020</td>
<td style="text-align:right">Embedded deep learning system for firefighting applications</td>
</tr>
<tr>
<td style="text-align:left">
<a href="https://www.linkedin.com/in/hans-hofner/" target="_blank" rel="noopener">Hans Hofner</a></td>
<td style="text-align:left">
<a href="https://www.unm.edu/" target="_blank" rel="noopener">UNM</a></td>
<td style="text-align:right">2017</td>
<td style="text-align:right">Thermal Imaging object and human recognition</td>
</tr>
</tbody>
</table>
    </div>
</div>

<footer class="container-fluid text-center">
  <a href="#myPage" title="To Top">
    <span class="glyphicon glyphicon-chevron-up"></span>
  </a>
</footer>

<script>
$(document).ready(function(){
  // Add smooth scrolling to all links in navbar + footer link
  $(".navbar a, footer a[href='#myPage']").on('click', function(event) {
    // Make sure this.hash has a value before overriding default behavior
    if (this.hash !== "") {
      // Prevent default anchor click behavior
      event.preventDefault();

      // Store hash
      var hash = this.hash;

      // Using jQuery's animate() method to add smooth page scroll
      // The optional number (900) specifies the number of milliseconds it takes to scroll to the specified area
      $('html, body').animate({
        scrollTop: $(hash).offset().top
      }, 900, function(){

        // Add hash (#) to URL when done scrolling (default click behavior)
        window.location.hash = hash;
      });
    } // End if
  });

  $(window).scroll(function() {
    $(".slideanim").each(function(){
      var pos = $(this).offset().top;

      var winTop = $(window).scrollTop();
        if (pos < winTop + 600) {
          $(this).addClass("slide");
        }
    });
  });
})
</script>

</body>
</html>
